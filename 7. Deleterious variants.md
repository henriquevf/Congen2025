8# ConGen 2025 - Deleterious variants tutorial

## Introduction

[SnpEff](https://pcingola.github.io/SnpEff/snpeff/introduction/) and [SnpSift](https://pcingola.github.io/SnpEff/snpsift/introduction/) are powerful tools designed for annotating and analyzing genetic variants, with a focus on deleterious variants. This tutorial will guide you through the process of using these tools to work with non-model organisms. 
SnpEff is a tool for annotating and analyzing genetic variants, with a focus on deleterious variants. There are prebuild databases for thousands of species, but if you're working with non-model organisms, you might have to create a custom SnpEff database using the organism's reference genome and annotation files. The annotation files usually include gene models in GFF3, GTF, or Gencode format. Another option is to map your reads to a closely related species that already has its genome in the SnpEff database.

### 1) Preparing the annotation database - Creating a custom SnpEff database

To create a custom SnpEff database, follow these steps:

a. Download the SnpEff software and set up the environment:

```bash
cd /anvil/scratch/YOUR_USERNAME/07_deleterious_variants
wget http://sourceforge.net/projects/snpeff/files/snpEff_latest_core.zip
unzip snpEff_latest_core.zip
cd snpEff
```

b. Create a new directory for your non-model organism in the data folder:

```bash
mkdir data
mkdir data/elephant
```

c. Copy the reference genome (FASTA) and annotation (GFF3, GTF, or Gencode) files into the new directory:

```bash
cp /anvil/projects/x-bio240351/shared_data/annotation/sorted.Loxodonta_africana.loxAfr4.105.gff3 data/elephant/genes.gff
cp /anvil/projects/x-bio240351/shared_data/reference/Chromosomes.v2.fasta data/elephant/sequences.fa
```

d. Modify the snpEff.config file to include the new genome:

```bash
echo "elephant.genome : elephant" >> snpEff.config
```

e. Build the SnpEff database:

```bash
module load biocontainers/default
module load jvarkit
java -jar snpEff.jar build -gff3 -v elephant
```

### 2) Run the SnpEff to annotating variants 

With the custom SnpEff database created and the variants called, you can now annotate the variants using SnpEff:

```bash
#!/bin/bash
#SBATCH --job-name snpeff
#SBATCH -A bio240351  # Allocation name
#SBATCH --nodes=1         # Total # of nodes (must be 1 for serial job)
#SBATCH --ntasks=1        # Total # of MPI tasks (should be 1 for serial job)
#SBATCH --mem=2G          # Memory allocation
#SBATCH --time=0:30:00    # Total run time limit (hh:mm:ss)
#SBATCH -o /anvil/scratch/YOUR_USERNAME/logs/snpeff.o%j      # Name of stdout output file
#SBATCH -e /anvil/scratch/YOUR_USERNAME/logs/snpeff.e%j      # Name of stderr error file
#SBATCH -p wholenode  # Queue (partition) name

#Load needed packages
module load biocontainers/default
module load jvarkit

#Define the working directory
cd /anvil/scratch/YOUR_USERNAME/07_deleterious_variants/snpEff

#Run snpeff
java -jar snpEff.jar elephant /anvil/projects/x-bio240351/shared_data/vcf/LoxAfr4_elephant_no1stdegree_variable_sites_nomultiallelics_noindels_10dp_3het_chr1.vcf.gz -stats
 test_summary.html -csvStats test_summary.csv > elephant_annotated_output.vcf
```

Familiarize yourself with the outputs. SnpEff will produce:
1) An annotated vcf file. Check the info field (column X do the vcf) containing the annotation.

![Screenshot 2024-12-16 160012](https://github.com/user-attachments/assets/a53e24d4-10bf-4e15-8666-8937e4823912)


2) a text file summarizing the number of variant types per gene
3) an HTML file containing summary statistics about the variants and their annotations. Open in a web browser and explore it. 


### 4) Analyzing deleterious variants with SnpSift

SnpSift is a collection of tools that can be used to filter, sort, and analyze the annotated VCF files. 


#### 4.1) Impact factors

Let's start filtering the VCF annotation file by impact.
SnpEff classify the following impact factors for all our variants:

Impact factor|	Description
---|---
LOW | synonymous variants
MODERATE | non-synonymous variants
HIGH | non-sense variants (affect start, stop or reading frame)
MODIFIER | all other variants (for example intronic, UTRs, intergenic)

A more detailed description can be found [here](https://pcingola.github.io/SnpEff/snpeff/inputoutput)
We will focus on the classes 'MODERATE' and 'HIGH', assuming that they represent potentially deleterious variants (This will not always be true, but we will never know the exact effect of all mutations, not even in model organisms, and that's just something we have to live with!). However, to have something potentially neutral to compare with, we will keep the LOW category.

Create subsets of annotated SNP with HIGH and MODERATE impact variants:

```bash
#!/bin/bash
#SBATCH --job-name SnpSift
#SBATCH -A bio240351  # Allocation name
#SBATCH --nodes=1         # Total # of nodes (must be 1 for serial job)
#SBATCH --ntasks=1        # Total # of MPI tasks (should be 1 for serial job)
#SBATCH --mem=500M          # Memory allocation
#SBATCH --time=0:30:00    # Total run time limit (hh:mm:ss)
#SBATCH -o /anvil/scratch/YOUR_USERNAME/log/SnpSift.o%j      # Name of stdout output file
#SBATCH -e /anvil/scratch/YOUR_USERNAME/log/SnpSift.e%j      # Name of stderr error file
#SBATCH -p wholenode  # Queue (partition) name

#Load needed packages
module load biocontainers/default
module load jvarkit

#Define the working directory
cd /anvil/scratch/YOUR_USERNAME/07_deleterious_variants/snpEff

#Run snpSift
java -jar SnpSift.jar filter "ANN[0].IMPACT has 'HIGH'" elephant_annotated.vcf > high_impact_variants.vcf
java -jar SnpSift.jar filter "ANN[0].IMPACT has 'MODERATE'" elephant_annotated.vcf > moderate_impact_variants.vcf
```

#### 4.2) Masked and realized load

From the lectures, we recall that masked load comes from heterozygous deleterious mutations, and realized load comes from homozygous deleterious mutations. First we can just look at different genotype counts from one individual:

```bash
# First individual in column 10 (cut -f10 means extract the 10th column)
grep -v "##" high_impact_variants.vcf | cut -f10 | cut -f1 -d":" | sort | uniq -c
```

To look at the next individual we can replace cut -f10 with cut -f39. 

> [!IMPORTANT]
> :elephant::grey_question: `AM0001` is a Savanna Elephant and `DS1514` is a Forest Elephant. Do you notice some difference between the individuals? 

Now we use some more awk and unix tools to save heterozygous and homozygous alternative sites from high and moderate separately.

```bash
#!/bin/bash
#SBATCH --job-name prepLoadTable
#SBATCH -A bio240351  # Allocation name
#SBATCH --nodes=1         # Total # of nodes (must be 1 for serial job)
#SBATCH --ntasks=1        # Total # of MPI tasks (should be 1 for serial job)
#SBATCH --mem=50M          # Memory allocation
#SBATCH --time=0:30:00    # Total run time limit (hh:mm:ss)
#SBATCH -o /anvil/scratch/YOUR_USERNAME/logs/prepLoadTable.o%j      # Name of stdout output file
#SBATCH -e /anvil/scratch/YOUR_USERNAME/logs/prepLoadTable.e%j      # Name of stderr error file
#SBATCH -p wholenode  # Queue (partition) name

echo -e "Type\tInd\tLoad\tNumber" > Load_table.txt

for type in "moderate" "high"; do
  vcf_file="${type}_impact_variants.vcf"
  header=$(grep "^#CHROM" $vcf_file) || { echo "Error: Header not found in $vcf_file"; exit 1; }
  # Loop over the sample columns (sample names start from the 10th column in VCF)
  for col in $(seq 10 $(echo "$header" | awk '{print NF}')); do
    ind=$(echo "$header" | awk -v c=$col '{print $c}')
    echo "Processing individual: $ind in type: $type"
    grep -v "^#" $vcf_file | cut -f $col | cut -d ':' -f 1 | \
    awk -v OFS="\t" -v t="$type" -v i="$ind" '{if($1=="0/1"){masked++}else if($1=="1/1"){realized++}} \
      END{print t, i, "masked", (masked ? masked : 0), "\n" t, i, "realized", (realized ? realized : 0)}' >> Load_table.txt
  done
done
```

Now let's plot the results using the R script below.
Follow the steps below to load R in the Anvil server and plot the results:

- load the R module by entering `module load r/4.1.0` in the terminal.
- Then, start an R session by typing `R`.
- Copy and paste the commands in the script below in the terminal.
- Use `quit()` to close R.
- Use Anvil browser to visualize the output file `.png`.

```
library(tidyverse)
library(ggplot2)

# Set the file path and read the file into a data frame
file_path <- "Load_table.txt"
LOAD <- read.table(file_path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)

# Create a new column for colors based on Population
LOAD <- LOAD %>%
  mutate(PopulationColor = case_when(str_detect(Population, "^Savanna") ~ "darkorange", 
      str_detect(Population, "^Forest") ~ "darkgreen", TRUE ~ "gray"),
    Ind = factor(Ind, levels = unique(LOAD$Ind[order(str_detect(LOAD$Population, "Forest"), decreasing = TRUE)])))

# Make one bar for each individual, and one plot for each mutation type
plot <- ggplot(LOAD, aes(x = Population, y = Number, fill = PopulationColor)) +
  geom_boxplot() +
  facet_grid(Type ~ Load, scales = 'free_y') + 
  labs(x = "Population", y = "Number of deleterious mutations") +  
  scale_fill_identity() +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Save the plot to a file
ggsave("load.png", plot, width = 10, height = 6, dpi = 300)
```

> [!IMPORTANT]
> :elephant::grey_question: Do you see a difference in the number of deleterious mutations between the elephant species? What is the difference between 'HIGH' impact mutations and 'MODERATE' impact mutations? What is the difference between realized and masked load? How is the relation between heterozygosity and genetic load?

>[!NOTE] 
> Remember, this is just a very rough estimation of genetic load! Apart from finding the correct deleterious allele (which we ignored above), it might be necessary to account for differences in sequencing (if some individuals have more missing data, for example). One way to do this is to calculate load as the number of deleterious alleles per genotyped sites.


#### 4.3) Analyze the alleles
You may wonder: which of the two alleles in a site is the deleterious one?? SnpEff doesn't provide us with this information. We know that a mutation in a certain position causes a non-synonymous variation, and that this could be harmful. But for all we know, it could be our reference individual who is carrying the deleterious allele, and the other individuals carrying the 'normal' variant.

There are a few different ways to figure this out (see box below), but for now we will assume that the REFERENCE allele is 'normal', and that the ALTERNATIVE allele is deleterious.

> [!NOTE]
> **Finding out which allele is deleterious**
> In a large population, deleterious variants will most likely be selected against, and will never reach high frequencies. Therefore it is often safe to assume that the minor allele is the deleterious variant. But in a small population, we know that also deleterious variants can reach high frequencies just due to drift. 
And what if we only have a couple of samples in the first place? It is hard to tell which is the minor! 
Another option is to polarize the variants, which involves determining the ancestral allele and designating it as the 'normal' variant. This strategy has been widely used in conservation genetics. Polarization is particularly valuable when working with multiple populations/species and using a reference genome that is more closely related to one of the populations. In such cases, the population chosen as the reference may appear to have less variations simply because it is being treated as the reference. Thus, polarization helps mitigate any bias introduced by the reference genome.


A good method to see if our potentially deleterious sites are under more selective constraints than for example synonymous mutations, is to compare their allele frequency spectra.

a) First we'll just look at the genotypes (remove everything else)

```bash
grep -v "##" GuamRail_moderate_impact.recode.vcf | awk '{out=$1"\t"$2; for(i=10; i<=11; i++){split($i,s,":"); out=out"\t"s[1]}; print out}' |less
```

This is a good start to just get a feeling for the data.
Now we will use vcftools to calculate allele frequency for each site. This will create .frq output files that we can summarize into a little table.

b) Create a table header:

```bash
echo "Type Number Ref_freq Alt_freq" |sed 's/ /\t/g' >SFS.txt
```

c) Loop over the types, create a frequency table and summarize:

```bash
for type in "low" "moderate" "high"
do
  vcftools --vcf GuamRail_${type}_impact.recode.vcf --freq --out GuamRail_${type}_impact
  tail -n+2 GuamRail_${type}_impact.frq  |cut -f5,6 |sed 's/:/\t/g' | cut -f2,4 |sort |uniq -c |awk -v t=$type -v OFS="\t" '{print t,$0}' >>SFS.txt
done
```

The file SFS.txt contains the site frequency spectra for all the three types of mutations. 

d) Below is some R code you can use for plotting:


```r
require(tidyverse)

file<-"SFS.txt"
SFS<-file %>% read.table(header=TRUE) %>% as_tibble()

# Order the types
SFS$Type<-factor(SFS$Type, levels=c("high","moderate","low"))

ggplot(SFS, aes(x=Alt_freq, y=Number, fill=Type)) +
  geom_bar(stat="identity", position=position_dodge())
```

What do we see here? The sizes are so different between the types so they are hard to compare! We can try making the bars using relative sizes instead:

```r
#With relative sizes
SFS_rel <- SFS %>% group_by(Type) %>% mutate(Rel=Number/sum(Number))

ggplot(SFS_rel, aes(x=Alt_freq, y=Rel, fill=Type)) +
  geom_bar(stat="identity", position=position_dodge())
```

Now it looks better! We see that the 'HIGH' category is shifted to the left, and the 'LOW' category has relatively more sites with higher alternative frequency. Can you explain why?
