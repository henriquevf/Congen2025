# ConGen 2025 - Deleterious variants tutorial

## Introduction

[SnpEff](https://pcingola.github.io/SnpEff/snpeff/introduction/) and [SnpSift](https://pcingola.github.io/SnpEff/snpsift/introduction/) are powerful tools designed for annotating and analyzing genetic variants, with a focus on deleterious variants. This tutorial will guide you through the process of using these tools to work with non-model organisms. 
SnpEff is a tool for annotating and analyzing genetic variants, with a focus on deleterious variants. There are prebuild databases for thousands of species, but if you're working with non-model organisms, you might have to create a custom SnpEff database using the organism's reference genome and annotation files. The annotation files usually include gene models in GFF3, GTF, or Gencode format. Another option is to map your reads to a closely related species that already has its genome in the SnpEff database.

### 1) Preparing the custom annotation database in SnpEff

To create a custom SnpEff database, follow these steps:

a. Download the SnpEff software and set up the environment:

```bash
cd /anvil/scratch/YOUR_USERNAME/07_deleterious_variants
wget http://sourceforge.net/projects/snpeff/files/snpEff_latest_core.zip
unzip snpEff_latest_core.zip
cd snpEff
```

b. Create a new directory for your non-model organism in the data folder:

```bash
mkdir data
mkdir data/elephant
```

c. Copy the reference genome (FASTA) and annotation (GFF3, GTF, or Gencode) files into the new directory:

```bash
cp /anvil/projects/x-bio240351/shared_data/annotation/sorted.Loxodonta_africana.loxAfr4.105.gff3 data/elephant/genes.gff
cp /anvil/projects/x-bio240351/shared_data/reference/Chromosomes.v2.fasta data/elephant/sequences.fa
```

d. Modify the snpEff.config file to include the new genome:

```bash
echo "elephant.genome : elephant" >> snpEff.config
```

e. Build the SnpEff database:

```bash
module load biocontainers/default
module load jvarkit
java -jar snpEff.jar build -gff3 -v elephant
```

### 2) Run the SnpEff to annotating variants 

With the custom SnpEff database created and the variants called, you can now annotate the variants using SnpEff:

```bash
#!/bin/bash
#SBATCH --job-name snpeff
#SBATCH -A bio240351  # Allocation name
#SBATCH --nodes=1         # Total # of nodes (must be 1 for serial job)
#SBATCH --ntasks=1        # Total # of MPI tasks (should be 1 for serial job)
#SBATCH --mem=2G          # Memory allocation
#SBATCH --time=0:30:00    # Total run time limit (hh:mm:ss)
#SBATCH -o /anvil/scratch/YOUR_USERNAME/logs/snpeff.o%j      # Name of stdout output file
#SBATCH -e /anvil/scratch/YOUR_USERNAME/logs/snpeff.e%j      # Name of stderr error file
#SBATCH -p wholenode  # Queue (partition) name

#Load needed packages
module load biocontainers/default
module load jvarkit

#Define the working directory
cd /anvil/scratch/YOUR_USERNAME/07_deleterious_variants/snpEff

#Run snpeff
java -jar snpEff.jar elephant /anvil/projects/x-bio240351/shared_data/vcf/LoxAfr4_elephant_no1stdegree_variable_sites_nomultiallelics_noindels_10dp_3het_chr1.vcf.gz -stats
 test_summary.html -csvStats test_summary.csv > elephant_annotated.vcf
```

Familiarize yourself with the outputs. SnpEff will produce:
1) An annotated vcf file. Check the info field in the `vcf` containing the annotation using the command below:

```bash
less -S elephant_annotated_output.vcf
```

![Screenshot 2024-12-16 160012](https://github.com/user-attachments/assets/a53e24d4-10bf-4e15-8666-8937e4823912)


> [!IMPORTANT]
> What is the impact level (high, low, modifier, moderate) of the first mutation in the vcf file, in the chromosome chr1, position 3000155? Where is it located or which change it causes (intron_variant, intergenic_region, synonymous_variant...)? 

2) a text file summarizing the number of variant types per gene
3) an HTML file containing summary statistics about the variants and their annotations. Open in a web browser and explore it. 

> [!IMPORTANT]
> For how many chromosomes do we have data? Do we also have information on insertions and deletions (indels)? Among the impact effects (HIGH, LOW, MODERATE, MODIFIER) and functional classes (MISSENSE, NONSENSE, SILENT), which are the most common?

### 4) Analyzing deleterious variants with SnpSift

SnpSift is a collection of tools that can be used to filter, sort, and analyze the annotated VCF files. 


#### 4.1) Impact factors

Let's start filtering the VCF annotation file by impact.
SnpEff classify the following impact factors for all our variants:

Impact factor|	Description
---|---
LOW | synonymous variants
MODERATE | non-synonymous variants
HIGH | non-sense variants (affect start, stop or reading frame)
MODIFIER | all other variants (for example intronic, UTRs, intergenic)

A more detailed description can be found [here](https://pcingola.github.io/SnpEff/snpeff/inputoutput).

We will focus on the classes 'MODERATE' and 'HIGH', assuming that they represent potentially deleterious variants (This will not always be true, but we will never know the exact effect of all mutations, not even in model organisms, and that's just something we have to live with!). 

Create subsets of annotated SNP with HIGH and MODERATE impact variants:

```bash
#!/bin/bash
#SBATCH --job-name SnpSift
#SBATCH -A bio240351  # Allocation name
#SBATCH --nodes=1         # Total # of nodes (must be 1 for serial job)
#SBATCH --ntasks=1        # Total # of MPI tasks (should be 1 for serial job)
#SBATCH --mem=500M          # Memory allocation
#SBATCH --time=0:30:00    # Total run time limit (hh:mm:ss)
#SBATCH -o /anvil/scratch/YOUR_USERNAME/log/SnpSift.o%j      # Name of stdout output file
#SBATCH -e /anvil/scratch/YOUR_USERNAME/log/SnpSift.e%j      # Name of stderr error file
#SBATCH -p wholenode  # Queue (partition) name

#Load needed packages
module load biocontainers/default
module load jvarkit

#Define the working directory
cd /anvil/scratch/YOUR_USERNAME/07_deleterious_variants/snpEff

#Run snpSift
java -jar SnpSift.jar filter "ANN[0].IMPACT has 'HIGH'" elephant_annotated.vcf > high_impact_variants.vcf
java -jar SnpSift.jar filter "ANN[0].IMPACT has 'MODERATE'" elephant_annotated.vcf > moderate_impact_variants.vcf
```

#### 4.2) Masked and realized load

From the lectures, we recall that masked load comes from heterozygous deleterious mutations, and realized load comes from homozygous deleterious mutations. First we can just look at different genotype counts from one individual:

```bash
# First individual in column 10 (cut -f10 means extract the 10th column)
grep -v "##" high_impact_variants.vcf | cut -f10 | cut -f1 -d":" | sort | uniq -c
```

To look at the next individual we can replace cut -f10 with cut -f39. 

> [!IMPORTANT]
> :elephant::grey_question: `AM0001` is a Savanna Elephant and `DS1514` is a Forest Elephant. Do you notice some difference between the individuals? 

Now we use some more awk and unix tools to save heterozygous and homozygous alternative sites from high and moderate separately.

```bash
#!/bin/bash
#SBATCH --job-name prepLoadTable
#SBATCH -A bio240351  # Allocation name
#SBATCH --nodes=1         # Total # of nodes (must be 1 for serial job)
#SBATCH --ntasks=1        # Total # of MPI tasks (should be 1 for serial job)
#SBATCH --mem=50M          # Memory allocation
#SBATCH --time=0:30:00    # Total run time limit (hh:mm:ss)
#SBATCH -o /anvil/scratch/YOUR_USERNAME/logs/prepLoadTable.o%j      # Name of stdout output file
#SBATCH -e /anvil/scratch/YOUR_USERNAME/logs/prepLoadTable.e%j      # Name of stderr error file
#SBATCH -p wholenode  # Queue (partition) name

echo -e "Type\tInd\tLoad\tNumber" > Load_table.txt

for type in "moderate" "high"; do
  vcf_file="${type}_impact_variants.vcf"
  header=$(grep "^#CHROM" $vcf_file) || { echo "Error: Header not found in $vcf_file"; exit 1; }
  # Loop over the sample columns (sample names start from the 10th column in VCF)
  for col in $(seq 10 $(echo "$header" | awk '{print NF}')); do
    ind=$(echo "$header" | awk -v c=$col '{print $c}')
    echo "Processing individual: $ind in type: $type"
    grep -v "^#" $vcf_file | cut -f $col | cut -d ':' -f 1 | \
    awk -v OFS="\t" -v t="$type" -v i="$ind" '{if($1=="0/1"){masked++}else if($1=="1/1"){realized++}} \
      END{print t, i, "masked", (masked ? masked : 0), "\n" t, i, "realized", (realized ? realized : 0)}' >> Load_table.txt
  done
done
```

Now let's plot the results using the R script below.
Follow the steps below to load R in the Anvil server and plot the results:

- load the R module by entering `module load r/4.1.0` in the terminal.
- Then, start an R session by typing `R`.
- Copy and paste the commands in the script below in the terminal.
- Use `quit()` to close R.
- Use Anvil browser to visualize the output file `.png`.

```
library(tidyverse)
library(ggplot2)

# Set the file path and read the file into a data frame
file_path <- "Load_table.txt"
LOAD <- read.table(file_path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)

# Create a new column for colors based on Population
LOAD <- LOAD %>%
  mutate(PopulationColor = case_when(str_detect(Population, "^Savanna") ~ "darkorange", 
      str_detect(Population, "^Forest") ~ "darkgreen", TRUE ~ "gray"),
    Ind = factor(Ind, levels = unique(LOAD$Ind[order(str_detect(LOAD$Population, "Forest"), decreasing = TRUE)])))

# Make one bar for each individual, and one plot for each mutation type
plot <- ggplot(LOAD, aes(x = Population, y = Number, fill = PopulationColor)) +
  geom_boxplot() +
  facet_grid(Type ~ Load, scales = 'free_y') + 
  labs(x = "Population", y = "Number of deleterious mutations") +  
  scale_fill_identity() +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Save the plot to a file
ggsave("load.png", plot, width = 10, height = 6, dpi = 300)
```

> [!IMPORTANT]
> :elephant::grey_question: Do you see a difference in the number of deleterious mutations between the elephant species?
> How is the difference between realized and masked load?
> Before saying9 that one species harbors a greater number of deleterious mutations, what further analyses would you need to run to compare the relative excess of mutations? What is the main confounding factor in elephants that can bias this result?

>[!NOTE] 
> Remember, this is just a very rough estimation of genetic load! Apart from finding the correct deleterious allele (which we ignored above), it might be necessary to account for differences in sequencing (if some individuals have more missing data, for example). One way to do this is to calculate load as the number of deleterious alleles per genotyped sites.


#### 4.3) Analyze the alleles

You may wonder: which of the two alleles in a site is the deleterious one?? SnpEff doesn't provide us with this information. We know that a mutation in a certain position causes a non-synonymous variation, and that this could be harmful. But for all we know, it could be our reference individual who is carrying the deleterious allele, and the other individuals carrying the 'normal' variant.

There are a few different ways to figure this out (see box below), but for now we will assume that the REFERENCE allele is 'normal', and that the ALTERNATIVE allele is deleterious.

> [!NOTE]
> **Finding out which allele is deleterious**
> In a large population, deleterious variants will most likely be selected against, and will never reach high frequencies. Therefore it is often safe to assume that the minor allele is the deleterious variant. But in a small population, we know that also deleterious variants can reach high frequencies just due to drift. 
And what if we only have a couple of samples in the first place? It is hard to tell which is the minor! 
Another option is to polarize the variants, which involves determining the ancestral allele and designating it as the 'normal' variant. This strategy has been widely used in conservation genetics. Polarization is particularly valuable when working with multiple populations/species and using a reference genome that is more closely related to one of the populations. In such cases, the population chosen as the reference may appear to have less variations simply because it is being treated as the reference. Thus, polarization helps mitigate any bias introduced by the reference gen
A good method to see if our potentially deleterious sites are under more selective constraints than for example synonymous mutations, is to compare their allele frequency spectra.

a) Use the script below to create VCF files for 4 individuals of each species for each categoriy (high, moderate and low).

```bash
#!/bin/bash
#SBATCH --job-name SnpSift
#SBATCH -A bio240351  # Allocation name
#SBATCH --nodes=1         # Total # of nodes (must be 1 for serial job)
#SBATCH --ntasks=1        # Total # of MPI tasks (should be 1 for serial job)
#SBATCH --mem=500M          # Memory allocation
#SBATCH --time=0:30:00    # Total run time limit (hh:mm:ss)
#SBATCH -o /anvil/scratch/YOUR_USERNAME/log/SnpSift.o%j      # Name of stdout output file
#SBATCH -e /anvil/scratch/YOUR_USERNAME/log/SnpSift.e%j      # Name of stderr error file
#SBATCH -p wholenode  # Queue (partition) name

#Load needed packages
module load biocontainers/default
module load vcftools

#Run vcftools

vcftools --vcf high_impact_variants.vcf --keep /anvil/projects/x-bio240351/shared_data/individuals_to_keep_savanna.txt --recode --out high_impact_variants_savanna
vcftools --vcf high_impact_variants.vcf --keep /anvil/projects/x-bio240351/shared_data/individuals_to_keep_forest.txt --recode --out high_impact_variants_forest

vcftools --vcf low_impact_variants.vcf --keep /anvil/projects/x-bio240351/shared_data/individuals_to_keep_savanna.txt --recode --out low_impact_variants_savanna
vcftools --vcf low_impact_variants.vcf --keep /anvil/projects/x-bio240351/shared_data/individuals_to_keep_forest.txt --recode --out low_impact_variants_forest

vcftools --vcf moderate_impact_variants.vcf --keep /anvil/projects/x-bio240351/shared_data/individuals_to_keep_savanna.txt --recode --out moderate_impact_variants_savanna
vcftools --vcf moderate_impact_variants.vcf --keep /anvil/projects/x-bio240351/shared_data/individuals_to_keep_forest.txt --recode --out moderate_impact_variants_forest
```


b) Now let's count allele types and plot results using the `vcfR` package in R. Load the R module by entering `module load r/4.1.0` in the terminal and start an R session by typing `R`. Copy and paste the commands in the script below in the terminal.

```r
# Load required libraries
install.packages("vcfR")
require(vcfR)
require(tidyverse)

# File names for the three VCF files
low_vcf_file <- "low_impact_variants_savanna.recode.vcf"
moderate_vcf_file <- "moderate_impact_variants_savanna.recode.vcf" 
high_vcf_file <- "high_impact_variants_savanna.recode.vcf" 

# Function to read a VCF and annotate it with its type
read_and_annotate_vcf <- function(vcf_file, type_label) {
  vcf <- read.vcfR(vcf_file)
  tidy_vcf <- vcfR2tidy(vcf, format_fields = c("GT"), dot_is_NA = TRUE)
  tidy_gt <- tidy_vcf$gt %>%
    filter(!is.na(gt_GT)) %>%
    inner_join(tidy_vcf$fix) %>%
    mutate(Type = type_label, 
           gt = paste(substr(gt_GT, 1, 1), substr(gt_GT, 3, 3), sep = ""))
  return(tidy_gt)
}

# Read and annotate each VCF file
low_tidy <- read_and_annotate_vcf(low_vcf_file, "low")
moderate_tidy <- read_and_annotate_vcf(moderate_vcf_file, "moderate")
high_tidy <- read_and_annotate_vcf(high_vcf_file, "high")

# Combine all tidy datasets into one
tidy_gt <- bind_rows(low_tidy, moderate_tidy, high_tidy)

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Building the SFS
SFS <- tidy_gt %>%
  select(CHROM, POS, Indiv, gt, Type) %>%
  group_by(CHROM, POS, gt, Type) %>%
  summarize(count = n()) %>%
  mutate(alt = case_when(
    gt == '11' ~ (count * 2.0),
    gt == '01' ~ (count * 1.0),
    TRUE ~ 0
  )) %>%
  group_by(CHROM, POS, Type) %>%
  summarize(totalt = sum(alt)) %>%
  group_by(Type, totalt) %>%
  summarize(count = n()) %>%
  ungroup() %>%
  group_by(Type) %>%
  mutate(Rel = count / sum(count))

# Order the types before plotting
SFS$Type <- factor(SFS$Type, levels = c("high", "moderate", "low"))

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Plot SFS
sfs_plot <- ggplot(SFS, aes(x = totalt, y = count, fill = Type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(x = "Alternative alleles", y = "Number of sites", title = "Site Frequency Spectrum")) 

# Save SFS plot as PNG
ggsave("SFS_plot.png", sfs_plot, width = 8, height = 6, dpi = 300)

```

What do we see here? The sizes are so different between the types so they are hard to compare! We can try making the bars using relative sizes instead:

```r
# Plot the SFS with relative sizes
sfs_rel_plot <- ggplot(SFS, aes(x = totalt, y = Rel, fill = Type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(x = "Alternative alleles", y = "Relative number of sites", 
       title = "Site Frequency Spectrum (Relative Sizes)") +
  theme_minimal()

# Save the relative SFS plot as PNG
ggsave("SFS_Rel_plot.png", sfs_rel_plot, width = 8, height = 6, dpi = 300)
```
Now it looks better! 

> [!IMPORTANT]
> :elephant::grey_question: Is there any difference between the High, Moderate, and Low categories?
> Which pattern do you expect if purifying selection is occurring?
> Click [here](https://onlinelibrary.wiley.com/doi/epdf/10.1111/mec.16802) to see the use of this code in the paper by Smeds & Ellegren (2023), in which the species is experiencing purging of deleterious variants.
