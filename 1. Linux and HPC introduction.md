# Introduction to Linux and HPC for Conservation Genomics

Welcome to the Linux and HPC tutorial for conservation genomics! In this session, weâ€™ll focus on the essential skills needed to navigate the command line, manage files, and run analyses on a high-performance computing (HPC) cluster.

**Why Linux and HPC for Conservation Genomics?

Whole-genome sequencing (WGS) generates large datasets that require powerful computational resources for analysis. HPC clusters provide the necessary infrastructure, but using them effectively requires familiarity with Linux, the command-line interface (CLI), and job scheduling systems.

## Section 1: Basics of the Linux Command Line

The Linux terminal is your gateway to controlling the HPC environment. Here are the basics to get you started:

### Logging into Purdue Anvil

Go to the website: https://ondemand.anvil.rcac.purdue.edu

Log in with your ACCESS login name and password

Navigate to Shell Access -> now you are on the command-line interface! 

## Navigation and File Management

This is called the shell, which is a computer program that allows you to control your computer using keyboard commands rather than using your mouse. Usually we only run commands like navigating directories, making a file, or deleting files on the command line. 

- Files are organized into directories, similar to folder structure on your laptop.
- The dollar sign is the "prompt", which you type commands on the command line to navigate the directory. We will get to running scripts later.
  
1.	**Navigating Directories**

â€¢	pwd â€“ Print your current directory:

```
pwd
```
When we log in, we are in our home directory: `/home/x-lhennelly`

We have other directories too. I will show the different directories on my computer and draw them on the board. 
- Scratch -> used to store large data files and output results from analyses.
```
cd /anvil/scratch/x-YOURNAME/
```

â€¢	ls â€“ List files in the current directory:
```
ls
```

- Home directory -> only used for storing you scripts, our out and error files, and small output files that are small in size
- Shared data for class -> all students have access to this directory, where we have the elephant data shared to run various analyses
```
cd /anvil/projects/x-bio240351/shared_data/
ls
```
â€¢	ls â€“ List files in the current directory:

```
cd /anvil/scratch/x-YOURNAME/
```

â€¢	mkdir â€“ Create a directory:

```
mkdir 01_linux_introduction 02_sequencing_dataquality 03_readmapping_variantcalling 04_population_structure  05_genetic_diversity 06_runs_of_homozygosity 07_deleterious_variants 08_demographic_inference 09_phylogenomic_introgression log
ls 
```
Now you should see the directories for different days of the course

â€¢	cd â€“ Change directory:

```
cd 01_linux_introduction
pwd
```
Now we are in the 01_linux_introduction directory

â€¢	Use cd .. to move up one directory.
```
cd ..
```

## Making and managing files

â€¢	touch â€“ Create an empty file:
```
cd 01_linux_introduction
touch file.txt
```

â€¢	cp â€“ Copy files:

```
cp file.txt /anvil/scratch/x-YOURNAME/
cd ..
ls
```

â€¢	rm â€“ Remove files:

```
rm /anvil/scratch/x-YOURNAME/file.txt
```

3.	**Viewing File Contents**

We can use less to view the inside of a file:
```
cd 01_linux_introduction
less file.txt
```

4.	**Editing Files**

â€¢	Use editors like vim:

```
vim file.txt
i
hello
ESC
:wq
ENTER
```

Using vim, we can copy and paste text into our text.file, and save it. Let's look at the file. 
```
less file.txt
```
Let's look at another file to practice some basic commands
```
cd /anvil/projects/x-bio240351/Day1
ls
less country.txt
less elephantlist.txt
```
We can paste the files together: 
```
paste elephantlist.txt country.txt > elephant_country.txt
less elephant_country.txt
```
We can use head and tail to look at first and last couple of lines: 
```
head elephant_country.txt
tail elephant_country.txt
```
We can use grep to find specific texts in the file and paste into a new file
```
grep Kenya elephant_country.txt > elephant_Kenya.txt
less elephant_Kenya.txt
```
We can also choose specific lines and columns in a file and paste into a new file: 
```
sed -n 15p elephant_country.txt
awk '{print $2}' elephant_country.txt 
```

## SCAVENGER HUNT
Let's practice changing directories and adjusting files with a small game. You will use the commands below to grab a specific letter for each command, and you will find out what word all the letters will spell.  
```
cd /anvil/projects/x-bio240351/Day1/Game
less file1.txt
sed -n 9p file1.txt
less file2.txt
awk '{print $5}' file2.txt
tail -n 1 file3.txt
head -n 1 file3.txt
grep "o" file2.txt 
awk '/next/ {print}' file4.txt
grep -v "d" file6.txt
```
> [!IMPORTANT]
> â“ðŸ˜ What is the final word? 


## Section 2: Using an HPC Cluster

HPC clusters are shared resources with multiple users and nodes for heavy computations. Hereâ€™s how to interact with them.

## Understanding HPC Components

â€¢	**Login Node**: The entry point where you manage files and submit jobs.

â€¢	**Compute Node**: Where your jobs are executed.

â€¢	**Scheduler**: Manages job queues (e.g., SLURM, PBS, or LSF).

**Job Submission with SLURM**

SLURM (Simple Linux Utility for Resource Management) is a common scheduler. You interact with SLURM using scripts and commands.

1.	**Writing a Job Script**

First we will go back into our home directory and make the job script: 
```
cd /home/x-lhennelly/01_linux_introduction
touch 01_testscript.sh
```

Then we will copy and paste the text below into the  `01_testscript.sh` 
```
vim 01_testscript.sh
i
copy and paste exmample job script below
ESC
:wq
```
Example job script (job_script.sh):

```
#!/bin/bash
#SBATCH --job-name testscript
#SBATCH -A bio240351  # Allocation name
#SBATCH --nodes=1         # Total # of nodes (must be 1 for serial job)
#SBATCH --ntasks=1        # Total # of MPI tasks (should be 1 for serial job)
#SBATCH --time=1:30:00    # Total run time limit (hh:mm:ss)
#SBATCH -o /anvil/scratch/YOUR_USERNAME/log/testscript.o%j      # Name of stdout output file
#SBATCH -e /anvil/scratch/YOUR_USERNAME/log/testscript.e%j      # Name of stderr error file
#SBATCH -p wholenode  # Queue (partition) name

awk 'FNR>=20 && FNR<=40' /anvil/projects/x-bio240351/Day1/elephant_country.txt > /anvil/projects/x-bio240351/Day1/elephant_country_specific.txt
```

2.	**Submitting a Job**

Use sbatch to submit:

```bash
sbatch 01_testscript.sh
```

3.	**Monitoring Jobs**

â€¢	squeue â€“ Check the status of jobs:

```bash
squeue -u your_username
```

â€¢	scancel â€“ Cancel a job:

```bash
scancel job_id
```

4.	**Checking Job Output**

After your job finishes, check the output files specified in the script (output.log, error.log).
```
cd /anvil/scratch/YOUR_USERNAME/log/
ls
less testscript.o*
less testscript.e* 
```
And let's see if the job worked by comparing line number of old and new file: 
```
wc -l /anvil/projects/x-bio240351/Day1/elephant_country.txt
wc -l /anvil/projects/x-bio240351/Day1/elephant_country_specific.txt
```
> [!IMPORTANT]
> How many lines are in the old and output file? 

## Modules for population genomic analyses 
For running many population genomic analyses, we need specific software to analyze our dataset. This is similar to R, where there are specific R packages written and published by other researchers that will download and use in our own research. 

The Purdue Anvil cluster already has many software already installed. We can check which software is installed on the Anvil cluster using: 
```
module avail
```
This is a list of many softwares that are already installed on our server. 

What output do you get when you write what's below in the terminal: 
```
samtools
```
Now load the module and try writing samtools again: 
```
module load samtools
samtools
```


ðŸ’¡ ### Section 4: Best Practices

1.	**Use Descriptive Names**: For directories, files, and job scripts.

2.	**Check Resource Usage**: Avoid over-requesting memory or CPUs.

3.	**Automate Repetitive Tasks**: Use Bash loops or scripts.

4.	**Keep Logs**: Redirect output and error streams for troubleshooting.

5.	**Clean Up**: Remove intermediate files after use to save storage.

**Resources**

â€¢	[Linux Command Cheat Sheet](https://www.linuxcommand.org/)

â€¢	[SLURM Documentation](https://slurm.schedmd.com/documentation.html)

â€¢	[Bioinformatics Tools Documentation](https://bioinformatics.org/tools/)

By the end of this tutorial, you should be comfortable navigating a Linux environment and submitting jobs to an HPC cluster. These skills are foundational for performing WGS analyses in conservation genomics. Letâ€™s dive in!
